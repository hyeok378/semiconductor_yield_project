{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29021580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/uci-secom.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b45688",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f43f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a1b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['31'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f3d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Pass/Fail'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d949648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Time'과 'Pass/Fail' 컬럼을 제외한 센서 데이터 특성들 선택\n",
    "features = df.drop(columns=['Time', 'Pass/Fail'])\n",
    "\n",
    "# 시작 인덱스를 지정하여 10개씩 반복해서 시각화\n",
    "start_index = 5  # 이 값을 10, 20, 30 등으로 변경하여 다음 10개 특성을 볼 수 있습니다.\n",
    "end_index = start_index + 10\n",
    "\n",
    "# 서브플롯 생성: 5행 2열 구조\n",
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(10, 15))\n",
    "axes = axes.flatten()  # 2차원 배열을 1차원으로 변환하여 쉽게 접근\n",
    "\n",
    "# 선택된 10개 특성에 대한 히스토그램 그리기\n",
    "for i, col in enumerate(features.columns[start_index:end_index]):\n",
    "    sns.histplot(data=features, x=col, kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Histogram of Feature {col}')\n",
    "    axes[i].set_xlabel('Value')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()  # 그래프 간 간격 자동 조절\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 예시로 '0'번 특성(컬럼)의 박스플롯 확인\n",
    "# '0' 대신 다른 특성 번호를 넣어 여러 컬럼 확인\n",
    "feature_to_plot = '100'\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=df[feature_to_plot])\n",
    "plt.title(f'Boxplot of Feature {feature_to_plot}')\n",
    "plt.xlabel(f'Feature {feature_to_plot} Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8729a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Time' 컬럼과 'Pass/Fail' 컬럼 -> 제외하고 결측치 처리\n",
    "features = df.drop(columns=['Time', 'Pass/Fail'])\n",
    "\n",
    "# 각 특성(feature)의 중앙값 계산\n",
    "median_values = features.median()\n",
    "\n",
    "# 중앙값을 사용하여 결측치 채우기\n",
    "df_filled = features.fillna(median_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36cf966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 모두 채워졌는지 확인\n",
    "print(df_filled.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bf0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 독립 변수(X)와 종속 변수(y) 분리\n",
    "X = df_filled\n",
    "y = df['Pass/Fail']\n",
    "\n",
    "# 훈련 및 테스트 데이터 분할\n",
    "# 'stratify=y'를 사용해 클래스 비율을 유지\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce0f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. 데이터 로드 및 초기 탐색 ---\n",
      "원본 데이터셋 크기: (1567, 592)\n",
      "Pass/Fail 컬럼의 고유값: [-1  1]\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- 2. 데이터 전처리 (결측치 처리 및 레이블 변환) ---\n",
      "변환 후 Pass/Fail 컬럼의 고유값: [0 1]\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- 3. 훈련 및 테스트 데이터 분할 ---\n",
      "훈련 데이터 크기: (1253, 590), 테스트 데이터 크기: (314, 590)\n",
      "훈련 데이터의 클래스 비율:\n",
      " Pass/Fail\n",
      "0    0.933759\n",
      "1    0.066241\n",
      "Name: proportion, dtype: float64\n",
      "테스트 데이터의 클래스 비율:\n",
      " Pass/Fail\n",
      "0    0.933121\n",
      "1    0.066879\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- 4. 초기 모델링 및 성능 평가 ---\n",
      "--- 로지스틱 회귀 모델 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ygh04\\Desktop\\semiconductor_yield_project\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.6709\n",
      "F1-Score: 0.0667\n",
      "Recall: 0.0476\n",
      "--- 성능 보고서 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       293\n",
      "           1       0.11      0.05      0.07        21\n",
      "\n",
      "    accuracy                           0.91       314\n",
      "   macro avg       0.52      0.51      0.51       314\n",
      "weighted avg       0.88      0.91      0.89       314\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- 랜덤 포레스트 모델 ---\n",
      "AUC: 0.7538\n",
      "F1-Score: 0.0000\n",
      "Recall: 0.0000\n",
      "--- 성능 보고서 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97       293\n",
      "           1       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.93       314\n",
      "   macro avg       0.47      0.50      0.48       314\n",
      "weighted avg       0.87      0.93      0.90       314\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- XGBoost 모델 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ygh04\\Desktop\\semiconductor_yield_project\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:17:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7062\n",
      "F1-Score: 0.0000\n",
      "Recall: 0.0000\n",
      "--- 성능 보고서 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97       293\n",
      "           1       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.93       314\n",
      "   macro avg       0.47      0.50      0.48       314\n",
      "weighted avg       0.87      0.93      0.90       314\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, classification_report\n",
    "\n",
    "# 1. 데이터 로드\n",
    "print(\"--- 1. 데이터 로드 및 초기 탐색 ---\")\n",
    "df = pd.read_csv('../data/uci-secom.csv')\n",
    "print(\"원본 데이터셋 크기:\", df.shape)\n",
    "print(\"Pass/Fail 컬럼의 고유값:\", df['Pass/Fail'].unique())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# 2. 데이터 전처리\n",
    "print(\"--- 2. 데이터 전처리 (결측치 처리 및 레이블 변환) ---\")\n",
    "# 'Time' 컬럼과 'Pass/Fail' 컬럼 제외\n",
    "features = df.drop(columns=['Time', 'Pass/Fail'])\n",
    "\n",
    "# 각 특성(feature)의 중앙값 계산\n",
    "median_values = features.median()\n",
    "\n",
    "# 중앙값을 사용하여 결측치 채우기\n",
    "df_filled = features.fillna(median_values)\n",
    "\n",
    "# 'Pass/Fail' 컬럼의 -1 값을 0으로 변환하여 모델이 인식할 수 있게 함\n",
    "y = df['Pass/Fail'].replace(-1, 0)\n",
    "print(\"변환 후 Pass/Fail 컬럼의 고유값:\", y.unique())\n",
    "\n",
    "# 독립 변수(X)와 종속 변수(y) 분리\n",
    "X = df_filled\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# 3. 훈련 및 테스트 데이터 분할\n",
    "print(\"--- 3. 훈련 및 테스트 데이터 분할 ---\")\n",
    "# 'stratify=y'를 사용해 클래스 비율을 유지\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"훈련 데이터 크기: {X_train.shape}, 테스트 데이터 크기: {X_test.shape}\")\n",
    "print(\"훈련 데이터의 클래스 비율:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"테스트 데이터의 클래스 비율:\\n\", y_test.value_counts(normalize=True))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# 4. 초기 모델링 (Baseline Modeling)\n",
    "print(\"--- 4. 초기 모델링 및 성능 평가 ---\")\n",
    "\n",
    "# 로지스틱 회귀 모델 훈련 및 평가\n",
    "print(\"--- 로지스틱 회귀 모델 ---\")\n",
    "lr_model = LogisticRegression(random_state=42, solver='liblinear')\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "lr_pred_proba = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"AUC: {roc_auc_score(y_test, lr_pred_proba):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, lr_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, lr_pred):.4f}\")\n",
    "print(\"--- 성능 보고서 ---\")\n",
    "print(classification_report(y_test, lr_pred, zero_division=0))\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# 랜덤 포레스트 모델 훈련 및 평가\n",
    "print(\"--- 랜덤 포레스트 모델 ---\")\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"AUC: {roc_auc_score(y_test, rf_pred_proba):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, rf_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, rf_pred):.4f}\")\n",
    "print(\"--- 성능 보고서 ---\")\n",
    "print(classification_report(y_test, rf_pred, zero_division=0))\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# XGBoost 모델 훈련 및 평가\n",
    "print(\"--- XGBoost 모델 ---\")\n",
    "xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"AUC: {roc_auc_score(y_test, xgb_pred_proba):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, xgb_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, xgb_pred):.4f}\")\n",
    "print(\"--- 성능 보고서 ---\")\n",
    "print(classification_report(y_test, xgb_pred, zero_division=0))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
