{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29021580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ygh04\\Desktop\\semiconductor_yield_project\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf1b7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74c8a4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Time        0        1          2          3       4      5  \\\n",
      "0  2008-07-19 11:55:00  3030.93  2564.00  2187.7333  1411.1265  1.3602  100.0   \n",
      "1  2008-07-19 12:32:00  3095.78  2465.14  2230.4222  1463.6606  0.8294  100.0   \n",
      "2  2008-07-19 13:17:00  2932.61  2559.94  2186.4111  1698.0172  1.5102  100.0   \n",
      "3  2008-07-19 14:43:00  2988.72  2479.90  2199.0333   909.7926  1.3204  100.0   \n",
      "4  2008-07-19 15:22:00  3032.24  2502.87  2233.3667  1326.5200  1.5334  100.0   \n",
      "\n",
      "          6       7       8  ...       581     582     583     584      585  \\\n",
      "0   97.6133  0.1242  1.5005  ...       NaN  0.5005  0.0118  0.0035   2.3630   \n",
      "1  102.3433  0.1247  1.4966  ...  208.2045  0.5019  0.0223  0.0055   4.4447   \n",
      "2   95.4878  0.1241  1.4436  ...   82.8602  0.4958  0.0157  0.0039   3.1745   \n",
      "3  104.2367  0.1217  1.4882  ...   73.8432  0.4990  0.0103  0.0025   2.0544   \n",
      "4  100.3967  0.1235  1.5031  ...       NaN  0.4800  0.4766  0.1045  99.3032   \n",
      "\n",
      "      586     587     588       589  Pass/Fail  \n",
      "0     NaN     NaN     NaN       NaN         -1  \n",
      "1  0.0096  0.0201  0.0060  208.2045         -1  \n",
      "2  0.0584  0.0484  0.0148   82.8602          1  \n",
      "3  0.0202  0.0149  0.0044   73.8432         -1  \n",
      "4  0.0202  0.0149  0.0044   73.8432         -1  \n",
      "\n",
      "[5 rows x 592 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/uci-secom.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b45688",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f43f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a1b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['31'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f3d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Pass/Fail'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d949648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Time'과 'Pass/Fail' 컬럼을 제외한 센서 데이터 특성들 선택\n",
    "features = df.drop(columns=['Time', 'Pass/Fail'])\n",
    "\n",
    "# 시작 인덱스를 지정하여 10개씩 반복해서 시각화\n",
    "start_index = 5  # 이 값을 10, 20, 30 등으로 변경하여 다음 10개 특성을 볼 수 있습니다.\n",
    "end_index = start_index + 10\n",
    "\n",
    "# 서브플롯 생성: 5행 2열 구조\n",
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(10, 15))\n",
    "axes = axes.flatten()  # 2차원 배열을 1차원으로 변환하여 쉽게 접근\n",
    "\n",
    "# 선택된 10개 특성에 대한 히스토그램 그리기\n",
    "for i, col in enumerate(features.columns[start_index:end_index]):\n",
    "    sns.histplot(data=features, x=col, kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Histogram of Feature {col}')\n",
    "    axes[i].set_xlabel('Value')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()  # 그래프 간 간격 자동 조절\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 예시로 '0'번 특성(컬럼)의 박스플롯 확인\n",
    "# '0' 대신 다른 특성 번호를 넣어 여러 컬럼 확인\n",
    "feature_to_plot = '100'\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=df[feature_to_plot])\n",
    "plt.title(f'Boxplot of Feature {feature_to_plot}')\n",
    "plt.xlabel(f'Feature {feature_to_plot} Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab8729a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Time' 컬럼과 'Pass/Fail' 컬럼 -> 제외하고 결측치 처리\n",
    "features = df.drop(columns=['Time', 'Pass/Fail'])\n",
    "\n",
    "# 각 특성(feature)의 중앙값 계산\n",
    "median_values = features.median()\n",
    "\n",
    "# 중앙값을 사용하여 결측치 채우기\n",
    "df_filled = features.fillna(median_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f36cf966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# 결측치 모두 채워졌는지 확인\n",
    "print(df_filled.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1bf0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 독립 변수(X)와 종속 변수(y) 분리\n",
    "X = df_filled\n",
    "y = df['Pass/Fail']\n",
    "\n",
    "# 훈련 및 테스트 데이터 분할\n",
    "# 'stratify=y'를 사용해 클래스 비율을 유지\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22ce0f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. 데이터 로드 및 초기 탐색 ---\n",
      "원본 데이터셋 크기: (1567, 592)\n",
      "Pass/Fail 컬럼의 고유값: [-1  1]\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- 2. 데이터 전처리 (결측치 처리 및 레이블 변환) ---\n",
      "변환 후 Pass/Fail 컬럼의 고유값: [0 1]\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- 3. 훈련 및 테스트 데이터 분할 ---\n",
      "훈련 데이터 크기: (1253, 590), 테스트 데이터 크기: (314, 590)\n",
      "훈련 데이터의 클래스 비율:\n",
      " Pass/Fail\n",
      "0    0.933759\n",
      "1    0.066241\n",
      "Name: proportion, dtype: float64\n",
      "테스트 데이터의 클래스 비율:\n",
      " Pass/Fail\n",
      "0    0.933121\n",
      "1    0.066879\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- 4. 초기 모델링 및 성능 평가 ---\n",
      "--- 로지스틱 회귀 모델 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ygh04\\Desktop\\semiconductor_yield_project\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.6709\n",
      "F1-Score: 0.0667\n",
      "Recall: 0.0476\n",
      "--- 성능 보고서 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       293\n",
      "           1       0.11      0.05      0.07        21\n",
      "\n",
      "    accuracy                           0.91       314\n",
      "   macro avg       0.52      0.51      0.51       314\n",
      "weighted avg       0.88      0.91      0.89       314\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- 랜덤 포레스트 모델 ---\n",
      "AUC: 0.7538\n",
      "F1-Score: 0.0000\n",
      "Recall: 0.0000\n",
      "--- 성능 보고서 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97       293\n",
      "           1       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.93       314\n",
      "   macro avg       0.47      0.50      0.48       314\n",
      "weighted avg       0.87      0.93      0.90       314\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- XGBoost 모델 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ygh04\\Desktop\\semiconductor_yield_project\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:13:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7062\n",
      "F1-Score: 0.0000\n",
      "Recall: 0.0000\n",
      "--- 성능 보고서 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97       293\n",
      "           1       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.93       314\n",
      "   macro avg       0.47      0.50      0.48       314\n",
      "weighted avg       0.87      0.93      0.90       314\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- 최종 결과 분석 ---\n",
      "다양한 모델의 초기 성능을 비교하고, 불균형 데이터에 중요한 지표인 Recall, F1-Score, AUC를 확인합니다.\n",
      "이 결과를 바탕으로 데이터 불균형을 해결할 모델을 선정하고, 다음 단계로 나아갈 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, classification_report\n",
    "\n",
    "# 1. 데이터 로드\n",
    "print(\"--- 1. 데이터 로드 및 초기 탐색 ---\")\n",
    "df = pd.read_csv('../data/uci-secom.csv')\n",
    "print(\"원본 데이터셋 크기:\", df.shape)\n",
    "print(\"Pass/Fail 컬럼의 고유값:\", df['Pass/Fail'].unique())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# 2. 데이터 전처리\n",
    "print(\"--- 2. 데이터 전처리 (결측치 처리 및 레이블 변환) ---\")\n",
    "# 'Time' 컬럼과 'Pass/Fail' 컬럼 제외\n",
    "features = df.drop(columns=['Time', 'Pass/Fail'])\n",
    "\n",
    "# 각 특성(feature)의 중앙값 계산\n",
    "median_values = features.median()\n",
    "\n",
    "# 중앙값을 사용하여 결측치 채우기\n",
    "df_filled = features.fillna(median_values)\n",
    "\n",
    "# 'Pass/Fail' 컬럼의 -1 값을 0으로 변환하여 모델이 인식할 수 있게 함\n",
    "y = df['Pass/Fail'].replace(-1, 0)\n",
    "print(\"변환 후 Pass/Fail 컬럼의 고유값:\", y.unique())\n",
    "\n",
    "# 독립 변수(X)와 종속 변수(y) 분리\n",
    "X = df_filled\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# 3. 훈련 및 테스트 데이터 분할\n",
    "print(\"--- 3. 훈련 및 테스트 데이터 분할 ---\")\n",
    "# 'stratify=y'를 사용해 클래스 비율을 유지\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"훈련 데이터 크기: {X_train.shape}, 테스트 데이터 크기: {X_test.shape}\")\n",
    "print(\"훈련 데이터의 클래스 비율:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"테스트 데이터의 클래스 비율:\\n\", y_test.value_counts(normalize=True))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# 4. 초기 모델링 (Baseline Modeling)\n",
    "print(\"--- 4. 초기 모델링 및 성능 평가 ---\")\n",
    "\n",
    "# 로지스틱 회귀 모델 훈련 및 평가\n",
    "print(\"--- 로지스틱 회귀 모델 ---\")\n",
    "lr_model = LogisticRegression(random_state=42, solver='liblinear')\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "lr_pred_proba = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"AUC: {roc_auc_score(y_test, lr_pred_proba):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, lr_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, lr_pred):.4f}\")\n",
    "print(\"--- 성능 보고서 ---\")\n",
    "print(classification_report(y_test, lr_pred, zero_division=0))\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# 랜덤 포레스트 모델 훈련 및 평가\n",
    "print(\"--- 랜덤 포레스트 모델 ---\")\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"AUC: {roc_auc_score(y_test, rf_pred_proba):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, rf_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, rf_pred):.4f}\")\n",
    "print(\"--- 성능 보고서 ---\")\n",
    "print(classification_report(y_test, rf_pred, zero_division=0))\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# XGBoost 모델 훈련 및 평가\n",
    "print(\"--- XGBoost 모델 ---\")\n",
    "xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"AUC: {roc_auc_score(y_test, xgb_pred_proba):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, xgb_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, xgb_pred):.4f}\")\n",
    "print(\"--- 성능 보고서 ---\")\n",
    "print(classification_report(y_test, xgb_pred, zero_division=0))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# 최종 결론 출력\n",
    "print(\"--- 최종 결과 분석 ---\")\n",
    "print(\"다양한 모델의 초기 성능을 비교하고, 불균형 데이터에 중요한 지표인 Recall, F1-Score, AUC를 확인합니다.\")\n",
    "print(\"이 결과를 바탕으로 데이터 불균형을 해결할 모델을 선정하고, 다음 단계로 나아갈 수 있습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
